# Partie 2 : Pipeline RAG

## Objectif

Mettre en pratique la conteneurisation et l'orchestration d'une application de G√©n√©ration Augment√©e par R√©cup√©ration (RAG) √† l'aide de Docker. Ce TP vous permettra de comprendre comment d√©ployer une application d'intelligence artificielle moderne en utilisant les meilleures pratiques DevOps.

### Structure des dossiers et fichiers

```
AIops-RAG/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # Point d'entr√©e principal de l'application
‚îÇ   ‚îú‚îÄ‚îÄ data/                        # Dossier des documents sources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DevOps_cours.txt         # Informations sur le cours DevOps
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensa_about.txt           # Description de l'ENSA
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensa_programs.md         # Programmes d'√©tudes (format Markdown)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ student_life.txt         # Vie √©tudiante et activit√©s
‚îÇ   ‚îú‚îÄ‚îÄ chroma_db/                   # Base de donn√©es vectorielle (g√©n√©r√©e)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chroma.sqlite3           # Stockage SQLite des m√©tadonn√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index/                   # Index de recherche vectorielle
‚îÇ   ‚îî‚îÄ‚îÄ utils/                       # Modules utilitaires
‚îÇ       ‚îú‚îÄ‚îÄ chat_interface.py        # Interface utilisateur Streamlit
‚îÇ       ‚îú‚îÄ‚îÄ embeddings.py            # Gestion des embeddings (vecteurs)
‚îÇ       ‚îî‚îÄ‚îÄ rag_pipeline.py          # Logique du pipeline RAG
‚îú‚îÄ‚îÄ docker-compose.yml               # Configuration d'orchestration Docker
‚îú‚îÄ‚îÄ Dockerfile                       # Instructions de construction de l'image
‚îú‚îÄ‚îÄ requirements.txt                 # D√©pendances Python
‚îú‚îÄ‚îÄ .env.example                     # Mod√®le de fichier d'environnement
‚îú‚îÄ‚îÄ .env                             # Variables d'environnement (cl√© API)
‚îî‚îÄ‚îÄ TP.md                            # Documentation du TP
```

## Qu'est-ce que le RAG ?

**RAG (Retrieval-Augmented Generation)** est une technique d'IA qui combine :

- **R√©cup√©ration** : Recherche d'informations pertinentes dans une base de donn√©es
- **G√©n√©ration** : Utilisation d'un mod√®le de langage (LLM) pour cr√©er des r√©ponses contextuelles

**Avantages du RAG** :

- R√©duit les hallucinations du mod√®le
- Permet de travailler avec des donn√©es priv√©es/sp√©cifiques
- Plus √©conomique que le fine-tuning complet
- Facilite la mise √† jour des connaissances

## Pr√©-requis

- **Docker Desktop** install√© ([T√©l√©charger](https://www.docker.com/products/docker-desktop))
  - _Pourquoi ?_ Permet de cr√©er des environnements isol√©s et reproductibles
- **Cl√© API Google Gemini** ([√Ä obtenir ici](https://aistudio.google.com/app/apikey))
  - _Pourquoi ?_ Acc√©der au mod√®le de langage Gemini pour la g√©n√©ration de texte

## √âtape 1 : Acqu√©rir le Projet

### 1.1 Fork du d√©p√¥t GitHub

**Action** : Dupliquer le d√©p√¥t sur votre profil GitHub

1. Rendez-vous sur le d√©p√¥t original
2. Cliquez sur le bouton "Fork" en haut √† droite
3. S√©lectionnez votre compte GitHub comme destination

**Pourquoi forker ?**

- Vous obtenez votre propre copie du projet
- Vous pouvez modifier sans affecter l'original
- Facilite la contribution et le suivi de vos modifications

### 1.2 Cloner le d√©p√¥t localement

**Outil utilis√©** : Git (syst√®me de contr√¥le de version)

```bash
git clone https://github.com/youssef-elkahlaoui/AIops_tp.git
cd AIops_tp
```

**Explication des commandes** :

- `git clone` : T√©l√©charge l'int√©gralit√© du d√©p√¥t sur votre machine
- `cd AIops_tp` : Se d√©place dans le r√©pertoire du projet

**Qu'est-ce qui est t√©l√©charg√© ?**

- Le code source de l'application
- Les fichiers de configuration Docker
- Les donn√©es d'exemple
- L'historique Git complet

### 1.3 Configuration de la cl√© API

**√âtape 1** : Cr√©er le fichier d'environnement

```bash
cp .env.example .env
```

**Pourquoi utiliser un fichier .env ?**

- S√©pare les secrets du code source
- √âvite d'exposer les cl√©s API dans Git
- Facilite la configuration pour diff√©rents environnements (dev, prod)

**√âtape 2** : Ins√©rer votre cl√© API

Ouvrez le fichier `.env` et modifiez-le :

```
GOOGLE_API_KEY=AIzaSy... (votre cl√© obtenue depuis Google AI Studio)
```

**S√©curit√©** :

- ‚ö†Ô∏è Ne commitez JAMAIS le fichier `.env` dans Git
- Le fichier `.gitignore` doit contenir `.env` pour √©viter cela
- Utilisez des variables d'environnement en production

## √âtape 2 : Conditionnement Docker

### 2.1 Qu'est-ce que Docker ?

**Docker** est une plateforme de conteneurisation qui permet de :

- Empaqueter une application avec toutes ses d√©pendances
- Garantir un fonctionnement identique sur tous les environnements
- Isoler l'application du syst√®me h√¥te

**Concepts cl√©s** :

- **Image Docker** : Mod√®le immuable contenant l'application et ses d√©pendances
- **Conteneur** : Instance en cours d'ex√©cution d'une image
- **Dockerfile** : Fichier de recette pour construire une image

### 2.2 Analyse du Dockerfile

Le fichier `Dockerfile` est d√©j√† pr√©sent dans le projet. Examinez son contenu ligne par ligne :

| Directive                                                             | Fonction                  | Explication d√©taill√©e                                                                                  |
| --------------------------------------------------------------------- | ------------------------- | ------------------------------------------------------------------------------------------------------ |
| `FROM python:3.9-slim`                                                | Image de base             | Utilise Python 3.9 dans une version l√©g√®re (sans paquets inutiles), r√©duit la taille de l'image finale |
| `WORKDIR /app`                                                        | R√©pertoire de travail     | D√©finit `/app` comme dossier principal o√π toutes les commandes seront ex√©cut√©es                        |
| `RUN apt-get update && apt-get install -y build-essential`            | D√©pendances syst√®me       | Installe les outils de compilation n√©cessaires pour ChromaDB (gcc, g++, make)                          |
| `COPY requirements.txt .`                                             | Transfert des d√©pendances | Copie uniquement le fichier de d√©pendances en premier (optimise le cache Docker)                       |
| `RUN pip install --no-cache-dir -r requirements.txt`                  | Installation Python       | Installe tous les packages Python n√©cessaires sans garder le cache (r√©duit la taille)                  |
| `COPY . .`                                                            | Transfert du code source  | Copie tout le code de l'application dans le conteneur                                                  |
| `EXPOSE 8501`                                                         | Exposition du port        | Indique que Streamlit √©coute sur le port 8501 (documentation, pas de s√©curit√© r√©elle)                  |
| `CMD ["streamlit", "run", "app/main.py", "--server.address=0.0.0.0"]` | Commande de d√©marrage     | Lance l'application Streamlit au d√©marrage du conteneur                                                |

### 2.3 Pourquoi cet ordre sp√©cifique ?

**Optimisation du cache Docker** :

1. Les couches qui changent rarement (image de base, d√©pendances syst√®me) sont en premier
2. `requirements.txt` est copi√© avant le code source
3. Le code source (qui change fr√©quemment) est copi√© en dernier

**Avantage** : Si vous modifiez seulement le code, Docker r√©utilise les couches pr√©c√©dentes (gain de temps consid√©rable)

### 2.4 Construction manuelle (optionnelle)

Pour comprendre le processus, vous pouvez construire l'image manuellement :

```bash
docker build -t rag-app:latest .
```

**Explication** :

- `docker build` : Commande de construction d'image
- `-t rag-app:latest` : Nomme l'image "rag-app" avec le tag "latest"
- `.` : Utilise le Dockerfile du r√©pertoire courant

**Processus de construction** :

1. Docker lit le Dockerfile
2. Ex√©cute chaque instruction dans l'ordre
3. Cr√©e une couche interm√©diaire pour chaque instruction
4. Produit l'image finale

## √âtape 3 : Gestion avec Docker Compose

### 3.1 Qu'est-ce que Docker Compose ?

**Docker Compose** est un outil d'orchestration qui permet de :

- D√©finir des applications multi-conteneurs
- G√©rer les configurations via un fichier YAML
- D√©marrer tous les services avec une seule commande
- G√©rer les r√©seaux et volumes automatiquement

**Pourquoi utiliser Docker Compose ?**

- Simplifie la gestion des conteneurs
- Configuration reproductible
- Id√©al pour les environnements de d√©veloppement
- Facilite la collaboration en √©quipe

### 3.2 Analyse du docker-compose.yml

Le fichier `docker-compose.yml` contient la configuration compl√®te de l'application. √âl√©ments typiques :

```yaml
version: "3.8" # Version du format Compose
services:
  rag-app: # Nom du service
    build: . # Construit depuis le Dockerfile local
    ports:
      - "8501:8501" # Mappe le port h√¥te:conteneur
    volumes:
      - ./app:/app/app # Monte le code pour hot-reload
    env_file:
      - .env # Charge les variables d'environnement
    restart: unless-stopped # Red√©marre automatiquement en cas d'erreur
```

**Explication des param√®tres** :

- **build** : Indique o√π trouver le Dockerfile
- **ports** : Permet d'acc√©der √† l'application depuis l'h√¥te
- **volumes** : Synchronise les fichiers entre h√¥te et conteneur (permet les modifications √† chaud)
- **env_file** : Charge les variables d'environnement depuis `.env`
- **restart** : Politique de red√©marrage automatique

### 3.3 D√©marrage de l'application

**Commande principale** :

```bash
docker-compose up --build
```

**D√©composition de la commande** :

- `docker-compose up` : Lance tous les services d√©finis
- `--build` : Force la reconstruction des images (utile apr√®s modification du code)

**Processus d√©taill√©** :

1. **Lecture du docker-compose.yml** : Docker Compose analyse la configuration
2. **Construction de l'image** : Ex√©cute le Dockerfile
   - T√©l√©chargement de l'image Python de base (~50 MB)
   - Installation des d√©pendances syst√®me (~100 MB)
   - Installation des packages Python (~200 MB)
   - Dur√©e totale : 3-5 minutes la premi√®re fois
3. **Cr√©ation du r√©seau** : R√©seau Docker isol√© pour le projet
4. **Montage des volumes** : Synchronisation des dossiers
5. **D√©marrage du conteneur** : Lance Streamlit
6. **Affichage des logs** : Montre la sortie en temps r√©el

**Indicateurs de r√©ussite** :

```
‚úì Network aiops-rag_default  Created
‚úì Container aiops-rag-app    Started
You can now view your Streamlit app in your browser.
Local URL: http://localhost:8501
```

### 3.4 Acc√®s √† l'interface

**URL** : [http://localhost:8501](http://localhost:8501)

**Que se passe-t-il ?**

1. Votre navigateur envoie une requ√™te au port 8501
2. Docker redirige vers le conteneur
3. Streamlit traite la requ√™te et renvoie l'interface web

**V√©rifications** :

- ‚úì La page se charge correctement
- ‚úì L'interface Streamlit s'affiche
- ‚úì Le panneau lat√©ral est visible

### 3.5 Commandes Docker Compose utiles

| Commande                           | Action                              | Quand l'utiliser                      |
| ---------------------------------- | ----------------------------------- | ------------------------------------- |
| `docker-compose up -d`             | Lance en arri√®re-plan               | Pour continuer √† utiliser le terminal |
| `docker-compose down`              | Arr√™te et supprime les conteneurs   | Pour nettoyer l'environnement         |
| `docker-compose logs -f`           | Affiche les logs en temps r√©el      | Pour d√©boguer                         |
| `docker-compose restart`           | Red√©marre les services              | Apr√®s modification de .env            |
| `docker-compose exec rag-app bash` | Ouvre un terminal dans le conteneur | Pour explorer l'int√©rieur             |

**Arr√™t de l'application** :

- M√©thode 1 : `Ctrl + C` dans le terminal
- M√©thode 2 : `docker-compose down` dans un autre terminal

## √âtape 4 : V√©rification de la Cha√Æne MLOps

### 4.1 Qu'est-ce qu'un pipeline MLOps ?

**MLOps** (Machine Learning Operations) applique les principes DevOps au machine learning :

- Automatisation du flux de donn√©es
- Reproductibilit√© des r√©sultats
- D√©ploiement continu des mod√®les
- Monitoring et maintenance

**Notre pipeline RAG** comporte 4 phases essentielles qui transforment des documents bruts en un syst√®me de question-r√©ponse intelligent.

### 4.2 Param√©trage Initial

**Actions √† effectuer** :

1. **Ouvrir l'interface** : [http://localhost:8501](http://localhost:8501)

2. **Localiser le panneau lat√©ral** (sidebar √† gauche)

   - Si masqu√©, cliquez sur la fl√®che en haut √† gauche

3. **Entrer la cl√© API Google**
   - Collez votre cl√© dans le champ pr√©vu
   - Format : `AIzaSy...` (environ 39 caract√®res)
4. **Lancer la construction** : Cliquez sur "Rebuild Vector Store"

**Pourquoi ce bouton ?**

- Initialise la base de donn√©es vectorielle
- Traite tous les documents du dossier `app/data/`
- Cr√©e les embeddings n√©cessaires pour la recherche s√©mantique

### 4.3 Phase 1 : Ingestion de Donn√©es

**Objectif** : Charger les documents sources dans le syst√®me

**Outil utilis√©** : `LangChain Document Loaders`

- `TextLoader` pour les fichiers `.txt`
- `UnstructuredMarkdownLoader` pour les fichiers `.md`

**Processus d√©taill√©** :

1. **Scan du dossier** : Le syst√®me parcourt `app/data/`
2. **D√©tection des fichiers** : Identifie les formats support√©s
3. **Lecture du contenu** : Charge chaque fichier en m√©moire
4. **Cr√©ation de documents** : Chaque fichier devient un objet Document avec :
   - `page_content` : Le texte du fichier
   - `metadata` : Nom du fichier, chemin, type

**Fichiers trait√©s** :

- ‚úì `DevOps_cours.txt` : Informations sur le cours DevOps
- ‚úì `ensa_about.txt` : Description de l'ENSA
- ‚úì `ensa_programs.md` : Liste des programmes d'√©tudes
- ‚úì `student_life.txt` : Vie √©tudiante et activit√©s

**R√©sultat attendu** :

```
Loaded 4 documents from app/data/
Total characters: ~5000
```

**Points de vigilance** :

- Les fichiers doivent √™tre en UTF-8
- Les noms de fichiers sans caract√®res sp√©ciaux
- Taille maximale recommand√©e : 5 MB par fichier

### 4.4 Phase 2 : Segmentation de Texte (Chunking)

**Objectif** : Diviser les documents en fragments g√©rables

**Outil utilis√©** : `RecursiveCharacterTextSplitter` de LangChain

**Pourquoi segmenter ?**

- Les mod√®les ont des limites de tokens
- Am√©liore la pr√©cision de la recherche
- R√©duit le co√ªt des API (moins de tokens trait√©s)
- Permet de retrouver des passages sp√©cifiques

**Param√®tres de segmentation** :

```python
chunk_size=1000        # Taille maximale d'un fragment (en caract√®res)
chunk_overlap=200      # Chevauchement entre fragments
```

**Pourquoi le chevauchement ?**

- √âvite de couper des informations importantes
- Maintient le contexte entre les chunks
- Am√©liore la qualit√© des r√©ponses

**Processus** :

1. **D√©coupage intelligent** :

   - Tente de couper aux sauts de paragraphe
   - Sinon aux points
   - Sinon aux virgules
   - En dernier recours : coupe au caract√®re

2. **Pr√©servation du contexte** :
   - Les 200 derniers caract√®res d'un chunk apparaissent dans le suivant
   - Les m√©tadonn√©es sont conserv√©es

**R√©sultat attendu** :

```
Split into 45 chunks
Average chunk size: 850 characters
```

**Exemple de chunk** :

```
Chunk 1: "L'ENSA Al Hoceima a √©t√© √©tablie en 2008..."
Chunk 2: "...√©tablie en 2008. Elle offre plusieurs programmes..."
```

### 4.5 Phase 3 : Cr√©ation d'Embeddings

**Objectif** : Transformer le texte en vecteurs num√©riques

**Qu'est-ce qu'un embedding ?**

- Repr√©sentation math√©matique du sens d'un texte
- Vecteur de nombres (ex: [0.23, -0.45, 0.67, ...])
- Les textes similaires ont des vecteurs proches

**Outil utilis√©** : `SentenceTransformers` avec le mod√®le `all-MiniLM-L6-v2`

**Caract√©ristiques du mod√®le** :

- **Dimensions** : 384 (taille du vecteur)
- **Langue** : Multilingue (fran√ßais, anglais, arabe)
- **Taille** : ~80 MB
- **Performance** : Excellent rapport qualit√©/vitesse

**Processus** :

1. **Chargement du mod√®le** : T√©l√©charg√© depuis Hugging Face (premi√®re fois uniquement)
2. **Encodage des chunks** :
   - Chaque chunk est transform√© en vecteur de 384 dimensions
   - Traitement par batch pour optimiser la vitesse
3. **Normalisation** : Les vecteurs sont normalis√©s pour la recherche par similarit√© cosinus

**Exemple simplifi√©** :

```
Texte: "L'ENSA offre des formations en g√©nie informatique"
‚Üí Embedding: [0.234, -0.456, 0.678, ..., 0.123]  (384 valeurs)
```

**Pourquoi ce mod√®le ?**

- ‚úì Rapide (environ 1000 chunks/seconde)
- ‚úì Fonctionne sans connexion internet apr√®s t√©l√©chargement
- ‚úì Gratuit et open-source
- ‚úì Bonne qualit√© pour le fran√ßais

**R√©sultat attendu** :

```
Generated 45 embeddings
Dimensions: 384
Model: all-MiniLM-L6-v2
```

### 4.6 Phase 4 : Sauvegarde Vectorielle

**Objectif** : Stocker les embeddings dans une base de donn√©es optimis√©e

**Outil utilis√©** : ChromaDB

**Qu'est-ce que ChromaDB ?**

- Base de donn√©es vectorielle open-source
- Optimis√©e pour la recherche de similarit√©
- Persistance sur disque
- Interface Python simple

**Processus de stockage** :

1. **Initialisation de ChromaDB** :

   - Cr√©ation du dossier `app/chroma_db/` si inexistant
   - Configuration de la collection "rag_collection"

2. **Insertion des donn√©es** :

   - Chaque chunk est stock√© avec :
     - Son embedding (vecteur)
     - Son contenu textuel
     - Ses m√©tadonn√©es (source, page, etc.)
     - Un ID unique

3. **Cr√©ation d'index** :
   - ChromaDB construit des index HNSW (Hierarchical Navigable Small World)
   - Permet des recherches ultra-rapides (millisecondes)

**Structure de stockage** :

```
chroma_db/
‚îú‚îÄ‚îÄ chroma.sqlite3        # Base de donn√©es SQLite
‚îú‚îÄ‚îÄ index/                # Index de recherche
‚îî‚îÄ‚îÄ metadata/             # M√©tadonn√©es
```

**Avantages de ChromaDB** :

- ‚úì Recherche rapide m√™me avec des millions de vecteurs
- ‚úì Persistance locale (pas besoin de serveur)
- ‚úì Mise √† jour incr√©mentale (ajouter sans tout recr√©er)
- ‚úì Gratuit et sans limites

**R√©sultat attendu** :

```
üíæ Vector store saved
Location: app/chroma_db/
Total documents: 45
Status: Ready for queries
```

### 4.7 R√©capitulatif du pipeline complet

**Flux de donn√©es** :

```
üìÑ Documents (.txt, .md)
    ‚Üì Phase 1: Ingestion
üìö Documents charg√©s en m√©moire
    ‚Üì Phase 2: Chunking
‚úÇÔ∏è Fragments de texte (1000 chars)
    ‚Üì Phase 3: Embeddings
üî¢ Vecteurs num√©riques (384 dimensions)
    ‚Üì Phase 4: Stockage
üíæ ChromaDB (recherche vectorielle)
    ‚Üì Utilisation
üí¨ Chatbot RAG op√©rationnel
```

**Temps d'ex√©cution typique** :

- Phase 1 : < 1 seconde
- Phase 2 : < 1 seconde
- Phase 3 : 5-10 secondes (selon nombre de chunks)
- Phase 4 : 2-3 secondes
- **Total** : ~15 secondes pour le jeu de donn√©es fourni

### 4.8 √âvaluer le Chatbot

**Objectif** : Tester la qualit√© du syst√®me RAG avec des questions vari√©es

**Comment fonctionne une requ√™te ?**

1. **Saisie de la question** : L'utilisateur tape dans le chat
2. **Embedding de la question** : Transformation en vecteur (384D)
3. **Recherche vectorielle** : ChromaDB trouve les chunks les plus similaires
4. **S√©lection du contexte** : Les 3 meilleurs chunks sont r√©cup√©r√©s
5. **Construction du prompt** : Combinaison du contexte + question
6. **Appel √† Gemini** : Le LLM g√©n√®re la r√©ponse
7. **Affichage** : La r√©ponse appara√Æt dans l'interface

**Tests √† effectuer** :

#### Test 1 : Question factuelle simple

**Question** : "Quand l'ENSA Al Hoceima a-t-elle √©t√© √©tablie ?"

**R√©ponse attendue** : "L'ENSA Al Hoceima a √©t√© √©tablie en 2008."

**Ce test valide** :

- ‚úì La recherche vectorielle fonctionne
- ‚úì Le chunk contenant la date est bien retrouv√©
- ‚úì Gemini extrait correctement l'information

#### Test 2 : Question n√©cessitant agr√©gation

**Question** : "Quels sont les clubs √©tudiants r√©pertori√©s ?"

**R√©ponse attendue** : Une liste des clubs mentionn√©s dans `student_life.txt`

**Ce test valide** :

- ‚úì Capacit√© √† retrouver plusieurs informations
- ‚úì Structuration de la r√©ponse (liste)
- ‚úì Exhaustivit√© de la recherche

#### Test 3 : Question en anglais

**Question** : "What programming languages are taught?"

**R√©ponse attendue** : Liste des langages de programmation du cursus

**Ce test valide** :

- ‚úì Support multilingue du mod√®le d'embeddings
- ‚úì Capacit√© de Gemini √† r√©pondre en anglais
- ‚úì Recherche cross-lingue (question EN, docs FR)

**Analyse de la qualit√©** :

**Bon indicateurs** :

- ‚úÖ R√©ponse pr√©cise et concise
- ‚úÖ Information directement extraite des documents
- ‚úÖ Pas d'invention d'informations (hallucination)
- ‚úÖ Citation implicite de la source

**Mauvais indicateurs** :

- ‚ùå R√©ponse g√©n√©rique ("Je ne sais pas")
- ‚ùå Information invent√©e non pr√©sente dans les docs
- ‚ùå R√©ponse hors sujet
- ‚ùå M√©lange de sources contradictoires

**Comprendre les limites** :

Si le chatbot r√©pond "Je n'ai pas cette information" :

1. **V√©rifiez** que le document contient bien l'info
2. **Reformulez** la question diff√©remment
3. **Chunking** : L'info est peut-√™tre coup√©e entre 2 chunks

**Panel de test avanc√©** :

| Type de question | Exemple                                | Difficult√©     |
| ---------------- | -------------------------------------- | -------------- |
| Factuelle        | "Quelle est la date de fondation ?"    | Facile         |
| Agr√©gation       | "Liste tous les programmes"            | Moyenne        |
| Comparaison      | "Quelle est la diff√©rence entre ..."   | Difficile      |
| Temporelle       | "Quand se d√©roule le cours X ?"        | Facile         |
| N√©gation         | "Quels clubs ne sont pas mentionn√©s ?" | Tr√®s difficile |

## √âtape 5 : Mise √† Jour Instantan√©e (Hot Reload)

### 5.1 Qu'est-ce que le Hot Reload ?

**Hot Reload** (rechargement √† chaud) est une fonctionnalit√© DevOps qui permet :

- Mise √† jour de l'application sans red√©marrage complet
- Synchronisation automatique des fichiers modifi√©s
- Gain de temps consid√©rable en d√©veloppement

**Comment √ßa fonctionne ici ?**

1. Docker monte le dossier `app/` local dans le conteneur
2. Streamlit d√©tecte les changements de fichiers
3. Le syst√®me recharge automatiquement les donn√©es

**Pourquoi c'est important ?**

- It√©ration rapide sur les donn√©es
- Pas besoin de `docker-compose down/up`
- La base vectorielle se met √† jour automatiquement
- Environnement de d√©veloppement agile

### 5.2 Objectif de ce test

**D√©montrer** que la cha√Æne MLOps peut int√©grer de nouvelles donn√©es sans n√©cessiter :

- Reconstruction de l'image Docker
- Red√©marrage du conteneur
- Intervention manuelle complexe

**Sc√©nario r√©el** : Un professeur ajoute des informations de derni√®re minute

### 5.3 Ajout d'un Nouveau Document

**√âtape 1** : Cr√©er le fichier `app/data/DevOps_cours.txt`

**Emplacement** : `c:\Users\jozef\OneDrive\Desktop\AIops-RAG\app\data\DevOps_cours.txt`

**M√©thode 1 - Via l'√©diteur** :

1. Ouvrir VS Code
2. Naviguer vers `app/data/`
3. Cr√©er un nouveau fichier : `DevOps_cours.txt`
4. Coller le contenu ci-dessous
5. Sauvegarder (`Ctrl+S`)

**M√©thode 2 - Via PowerShell** :

```powershell
cd app\data
New-Item -Path "DevOps_cours.txt" -ItemType File
notepad DevOps_cours.txt
```

**Contenu √† ins√©rer** :

```
Le cours de DevOps est dispens√© le mercredi matin √† 9 h.
Le professeur responsable est Dr. Bahri.
Les √©tudiants apprennent Docker, Kubernetes et CI/CD.
Le TP pratique couvre la conteneurisation d'applications.
```

**Pourquoi ce contenu ?**

- Information factuelle simple (date, heure)
- Nom propre sp√©cifique (Dr. Bahri)
- Termes techniques (Docker, Kubernetes)
- Facilement v√©rifiable dans les r√©ponses

### 5.4 Constater la D√©tection Automatique

**M√©canisme de surveillance** :

Le syst√®me utilise un **watchdog** (chien de garde) qui :

1. **Surveille** le dossier `app/data/` en permanence
2. **Calcule** un hash (empreinte num√©rique) du contenu
3. **Compare** avec le hash pr√©c√©dent
4. **D√©clenche** le rebuild si diff√©rence d√©tect√©e

**Processus automatique** :

```
üìÅ Fichier ajout√©/modifi√©
    ‚Üì
üîç D√©tection du changement (hash diff√©rent)
    ‚Üì
‚ö†Ô∏è Alerte "Data folder changes detected!"
    ‚Üì
üîÑ Rebuild automatique du vector store
    ‚Üì
‚úÖ Syst√®me √† jour
```

**Indicateurs visuels** :

1. **Actualisez** la page dans le navigateur (`F5`)

2. **Message attendu** dans le panneau lat√©ral :

   ```
   ‚ö†Ô∏è Data folder changes detected!
   The vector store needs to be rebuilt.
   ```

3. **Bouton activ√©** : "Rebuild Vector Store" devient cliquable

4. **Cliquez** sur le bouton pour lancer le rebuild

5. **Progression** : Les 4 phases se relancent
   - ‚úì Phase 1 : D√©tection de 5 documents (au lieu de 4)
   - ‚úì Phase 2 : Nouveau nombre de chunks
   - ‚úì Phase 3 : Embeddings recalcul√©s
   - ‚úì Phase 4 : ChromaDB mis √† jour

**Temps de rebuild** : 10-20 secondes

**Optimisation possible** :

- Version avanc√©e : Ne traiter que les nouveaux fichiers (delta update)
- Version actuelle : Rebuild complet (plus simple, plus fiable)

### 5.5 V√©rification technique (optionnelle)

**Inspecter les logs Docker** :

```powershell
docker-compose logs -f rag-app
```

**Messages attendus** :

```
[INFO] File watcher detected changes
[INFO] Starting vector store rebuild...
[INFO] Loaded 5 documents (1 new)
[INFO] Generated 52 chunks
[INFO] Vector store updated successfully
```

### 5.6 Interroger la Nouvelle Donn√©e

**Test 1 : Question temporelle**

**Question** : "Quand est pr√©vu le cours de DevOps ?"

**R√©ponse attendue** : "Le cours de DevOps est pr√©vu le mercredi matin √† 9h."

**Validation** :

- ‚úÖ Le syst√®me a bien index√© le nouveau fichier
- ‚úÖ La recherche vectorielle fonctionne sur les nouvelles donn√©es
- ‚úÖ L'information temporelle est correctement extraite

**Analyse** : Si la r√©ponse est incorrecte ou absente :

1. V√©rifiez que le fichier est bien dans `app/data/`
2. Confirmez que le rebuild a √©t√© effectu√©
3. Regardez les logs pour d'√©ventuelles erreurs

**Test 2 : Question sur personne**

**Question** : "Qui est le professeur responsable du cours de DevOps ?"

**R√©ponse attendue** : "Le professeur responsable du cours de DevOps est Dr. Bahri."

**Validation** :

- ‚úÖ Extraction de nom propre fonctionnelle
- ‚úÖ Association correcte (cours ‚Üî professeur)
- ‚úÖ Formulation naturelle de la r√©ponse

**Test 3 : Question technique**

**Question** : "Quelles technologies sont enseign√©es dans le cours de DevOps ?"

**R√©ponse attendue** : "Docker, Kubernetes et CI/CD"

**Validation** :

- ‚úÖ √ânum√©ration correcte
- ‚úÖ Pas d'ajout d'informations non pr√©sentes
- ‚úÖ Formatage lisible

### 5.7 Comprendre l'avantage du volume Docker

**Sans volume Docker** :

```yaml
# Mauvaise pratique
services:
  rag-app:
    build: .
    # Pas de volume
```

- ‚ùå Modifications de code non prises en compte
- ‚ùå N√©cessite `docker-compose up --build` √† chaque fois
- ‚ùå Perte de temps (3-5 minutes par rebuild)

**Avec volume Docker** (configuration actuelle) :

```yaml
# Bonne pratique
services:
  rag-app:
    build: .
    volumes:
      - ./app:/app/app # Synchronisation bidirectionnelle
```

- ‚úÖ Modifications instantan√©es
- ‚úÖ Workflow de d√©veloppement fluide
- ‚úÖ Rebuild uniquement si changement de d√©pendances

**Cas d'usage r√©els** :

- **D√©veloppement** : It√©ration rapide sur les donn√©es/code
- **D√©mo** : Ajout de donn√©es devant le client
- **Production** : ‚ö†Ô∏è √Ä d√©sactiver (stabilit√© requise)

### 5.8 Exp√©rimentations sugg√©r√©es

**Exercice 1** : Modifier un fichier existant

1. √âditez `app/data/ensa_about.txt`
2. Ajoutez une phrase
3. Observez la d√©tection automatique
4. Posez une question sur la nouvelle info

**Exercice 2** : Supprimer un document

1. Supprimez `app/data/student_life.txt`
2. Rebuild le vector store
3. Tentez une question sur les clubs
4. R√©sultat : "Information non disponible"

**Exercice 3** : Format Markdown

1. Cr√©ez `app/data/horaires.md`
2. Utilisez la syntaxe Markdown (titres, listes)
3. V√©rifiez que le syst√®me traite correctement le formatage

**Limites √† conna√Ætre** :

- Formats support√©s : `.txt`, `.md` uniquement
- Encodage : UTF-8 obligatoire
- Taille : √âviter les fichiers > 5 MB
- Noms : Pas de caract√®res sp√©ciaux (√©, √†, √ß, espaces)

---

## üéØ R√©capitulatif et Concepts Cl√©s

### Technologies et leur r√¥le

| Technologie              | R√¥le                | Alternatives possibles            |
| ------------------------ | ------------------- | --------------------------------- |
| **Docker**               | Conteneurisation    | Podman, LXC                       |
| **Docker Compose**       | Orchestration       | Kubernetes (pour production)      |
| **Python 3.9**           | Langage principal   | Python 3.10+, 3.11                |
| **Streamlit**            | Framework web       | Gradio, Flask, FastAPI            |
| **LangChain**            | Framework RAG       | LlamaIndex, Haystack              |
| **ChromaDB**             | Base vectorielle    | Pinecone, Weaviate, Milvus, FAISS |
| **SentenceTransformers** | Mod√®le d'embeddings | OpenAI Ada-002, Cohere            |
| **Google Gemini**        | LLM g√©n√©ratif       | GPT-4, Claude, Llama              |

### Concepts DevOps appliqu√©s

1. **Infrastructure as Code** : `Dockerfile` + `docker-compose.yml`
2. **Immutabilit√©** : Conteneurs identiques sur tous les environnements
3. **Isolation** : Application s√©par√©e du syst√®me h√¥te
4. **Reproductibilit√©** : Build identique partout
5. **Hot Reload** : D√©veloppement it√©ratif rapide
6. **Surveillance** : D√©tection automatique des changements
7. **Logs centralis√©s** : `docker-compose logs`

### Flux d'une requ√™te utilisateur

```
1. üí¨ Utilisateur : "Quand l'ENSA a-t-elle √©t√© cr√©√©e ?"
           ‚Üì
2. üî¢ Embedding : [0.23, -0.45, 0.67, ...] (384D)
           ‚Üì
3. üîç ChromaDB : Recherche par similarit√© cosinus
           ‚Üì
4. üìÑ Top 3 chunks :
   - "L'ENSA Al Hoceima √©tablie en 2008..." (score: 0.92)
   - "Histoire de l'√©tablissement..." (score: 0.87)
   - "Cr√©ation et d√©veloppement..." (score: 0.81)
           ‚Üì
5. üìù Construction du prompt :
   Contexte: [chunks r√©cup√©r√©s]
   Question: "Quand l'ENSA a-t-elle √©t√© cr√©√©e ?"
   Instruction: R√©ponds pr√©cis√©ment bas√© sur le contexte.
           ‚Üì
6. ü§ñ Gemini API : G√©n√©ration de la r√©ponse
           ‚Üì
7. ‚úÖ R√©ponse : "L'ENSA Al Hoceima a √©t√© cr√©√©e en 2008."
```

### M√©triques de performance

**Temps de r√©ponse typique** :

- Embedding de la question : ~50 ms
- Recherche vectorielle : ~10 ms
- Appel API Gemini : 1-3 secondes
- **Total** : 1-3 secondes

**Co√ªts** :

- Embeddings locaux : Gratuit (SentenceTransformers)
- ChromaDB : Gratuit (open-source)
- Gemini API : ~15 requ√™tes gratuites/minute
- **Co√ªt total pour ce TP** : 0 ‚Ç¨

**Scalabilit√©** :

- Documents : Jusqu'√† 10 000 sans probl√®me
- Requ√™tes simultan√©es : 10-50 (selon config serveur)
- Pour plus : Passer √† une architecture distribu√©e

---

## üèÉ Plan B : Ex√©cution Locale (Sans Docker)

### Quand utiliser cette m√©thode ?

- ‚ùå Docker Desktop ne fonctionne pas
- ‚ùå Probl√®mes de virtualisation (Hyper-V)
- ‚ùå Ressources syst√®me limit√©es
- ‚úÖ D√©veloppement rapide et l√©ger
- ‚úÖ D√©bogage approfondi n√©cessaire

### Pr√©requis syst√®me

- **Python** : Version 3.9, 3.10 ou 3.11 install√©e
- **Pip** : Gestionnaire de packages Python
- **Git** : Pour cloner le d√©p√¥t
- **Espace disque** : ~2 GB (mod√®les + d√©pendances)

### Installation pas √† pas

**√âtape 1** : V√©rifier Python

```powershell
python --version
```

**R√©sultat attendu** : `Python 3.9.x` ou sup√©rieur

**Si Python n'est pas install√©** :

1. T√©l√©charger depuis [python.org](https://www.python.org/downloads/)
2. Cocher "Add Python to PATH" pendant l'installation
3. Red√©marrer PowerShell

**√âtape 2** : Cr√©er un environnement virtuel

```powershell
# Se placer dans le dossier du projet
cd c:\Users\jozef\OneDrive\Desktop\AIops-RAG

# Cr√©er l'environnement virtuel
python -m venv venv

# Activer l'environnement (Windows)
.\venv\Scripts\Activate.ps1
```

**Pourquoi un environnement virtuel ?**

- Isole les d√©pendances du projet
- √âvite les conflits avec d'autres projets Python
- Facilite la gestion des versions de packages

**√âtape 3** : Installer les d√©pendances

```powershell
# Mettre √† jour pip
python -m pip install --upgrade pip

# Installer tous les packages requis
pip install -r requirements.txt
```

**Packages install√©s** (principaux) :

- `streamlit` : Framework web
- `langchain` : Framework RAG
- `chromadb` : Base vectorielle
- `sentence-transformers` : Mod√®le d'embeddings
- `google-generativeai` : SDK Gemini

**Temps d'installation** : 3-5 minutes

**√âtape 4** : Configurer la cl√© API

```powershell
# Copier le fichier d'exemple
copy .env.example .env

# √âditer avec notepad
notepad .env
```

Ins√©rer votre cl√© :

```
GOOGLE_API_KEY=AIzaSy...
```

**√âtape 5** : D√©marrer l'application

```powershell
# Lancer Streamlit
python -m streamlit run app/main.py
```

**Alternative** :

```powershell
streamlit run app/main.py
```

**Sortie attendue** :

```
You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.x:8501
```

**√âtape 6** : Acc√©der √† l'interface

Ouvrir [http://localhost:8501](http://localhost:8501) dans votre navigateur

## üìö Pour aller plus loin

**Documentation officielle** :

- [Docker](https://docs.docker.com/)
- [LangChain](https://python.langchain.com/)
- [ChromaDB](https://docs.trychroma.com/)
- [Streamlit](https://docs.streamlit.io/)

**Tutoriels avanc√©s** :

- [RAG from Scratch](https://github.com/langchain-ai/rag-from-scratch)
- [Vector Databases Explained](https://www.pinecone.io/learn/vector-database/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)

**Communaut√©s** :

- [LangChain Discord](https://discord.gg/langchain)
- [r/MachineLearning](https://reddit.com/r/MachineLearning)
- [Docker Community Forum](https://forums.docker.com/)

---
